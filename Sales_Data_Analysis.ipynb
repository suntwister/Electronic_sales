{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"LSU_xw-Dd7tZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1.0 Extract, Transform and Load"],"metadata":{"id":"pi2sKQdjWci_"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5MUolpJaKOyw","executionInfo":{"status":"ok","timestamp":1729865807895,"user_tz":420,"elapsed":52914,"user":{"displayName":"AbdulBasit OLAJIRE","userId":"13126082537182926041"}},"outputId":"b3e2f1fd-d6c2-4ffc-8d56-9e917f079150"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HVSpG_t2_O2I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731921525440,"user_tz":-60,"elapsed":6015,"user":{"displayName":"Emmanuel Odusanya","userId":"03074087659073814634"}},"outputId":"ba797add-4205-4de7-f243-c52a6506732b"},"outputs":[{"output_type":"stream","name":"stdout","text":["imported successes \n"]}],"source":["# import neccesary libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","print(\"imported successes \")"]},{"cell_type":"code","source":["#Load in the dataset\n","\n","sales = pd.read_csv(\"/content/sales_data.xls\")"],"metadata":{"id":"FL9rBNyX_lGv","executionInfo":{"status":"error","timestamp":1729865859867,"user_tz":420,"elapsed":555,"user":{"displayName":"AbdulBasit OLAJIRE","userId":"13126082537182926041"}},"colab":{"base_uri":"https://localhost:8080/","height":512},"outputId":"1b2b935c-57c2-4f13-a6f2-ba3ef9b46a56"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ParserError","evalue":"Error tokenizing data. C error: Expected 12 fields in line 10186, saw 17\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-caa384f05ab8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sales_data.xls\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 12 fields in line 10186, saw 17\n"]}]},{"cell_type":"code","source":["\n","## What makes a dirty data?\n","# Missing values\n","\n","# Duplicates\n","# inconsistent data columns\n","# wrong datatype ....>to change datatypes we use \".astype()\" ----> to check datatypes we use \"dtypes\"\n","# incomplete data\n","\n","## Why do we need to clean data? We clean data to ensure\n","# --->Data integrity, accuracy and consistency---->\n","\n","\n","## Data anaysis pipeline\n","#1. ETL (Extract, Transform and Load)\n","#2. creating data model for visualization\n","#3. building dashboard\n","#4. Reporting and presentation\n","\n","## Data Science pipeline\n","#1. Preliminary analysis\n","#2. EDA Exploratory data analysis\n","#3. Data cleaning\n","#4. Analysis(Data Wrangling)\n","#5. Data preprocessing and data mining\n","#6. Building your model(prediction, forcasting, classification, clustering)\n","#7. Reporting and visualization\n","#8. Deployment\n","#9. Maintenance and monitoring\n","#10.Support and troubleshooting\n","#----> Please note that from step2 to step5 is an iterative process that is dependent on step 6. Step 6 itself could also be iterative"],"metadata":{"id":"Zjen2EaD11vf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# View a snapshot of your dataset\n","sales.head()"],"metadata":{"id":"5LpYPoG3_0IA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Do a little bit of feature engineering\n","\n","# add revenue column\n","# To create a new column, you start with creating the new columns as a variable name\n","\n","# units X price = Revenue\n","# units * price = Revenue\n","\n","sales[\"Revenue\"] = sales[\"Units\"] * sales[\"Price\"]\n","\n","\n","# round(parameter,2)\n","sales[\"Revenue(N)\"] = round(sales[\"Units\"]*sales[\"Price\"] * 1000,2)\n"],"metadata":{"id":"CAb-U7tO_2Zg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Feature Engineering**\n","* Explanation:\n","\n","Feature Engineering- This means 3 things, one is useful here and the other two for machine learning. Feature engineering in this context, has to do with creating a new feature or column by combining, extracting or simply doing calculation on an existing column or feature."],"metadata":{"id":"UdVhnSisXhCG"}},{"cell_type":"code","source":["# view to sse if the changes has been effected\n","sales.head()"],"metadata":{"id":"XnrOwojSAN3P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# lets check data types\n","sales.dtypes"],"metadata":{"id":"dhD1i2R2BF9X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# lets convert the date column to datatime\n","# Using \"pd.to_datetime()\" function\n","\n","#to_datetime()\n","\n","# datetime()\n","sales[\"Date\"] = pd.to_datetime(sales[\"Date\"])"],"metadata":{"id":"jNmAk06XBOM3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# lets check our data types\n","sales.dtypes"],"metadata":{"id":"TyrxXfuSDOEO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# lets just plot  this, its not important though.\n","sales.dtypes.value_counts().plot(kind=\"bar\", xlabel = \"Data Types\", ylabel = \"Count\")"],"metadata":{"id":"4mRiBsb5DfCI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lets do more feature engineering\n","\n","# lets  work on our datetime to extract the month,year and week name\n","# using \".dt.year\",\".dt.month_name()\",\".day_name()\n","\n","sales[\"Year\"] = sales[\"Date\"].dt.year\n","sales[\"Month\"] = sales[\"Date\"].dt.month_name()\n","sales[\"Week\"] = sales[\"Date\"].dt.day_name()"],"metadata":{"id":"FgUXJ9YWElC2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sales.head()"],"metadata":{"id":"2MlmLscRFv99"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#2.0 Steps to Analysis\n","**Note:** This is after you have followed the ETL(Extract Transform Load) frame work, this is you importing your dataset, cleaning and preparing it for analysis\n","\n","### A. Work on the KPI's (Key performance index of this data)\n","1. Total units sold\n","2. Total Revenue\n","3. Average Revenue per unit\n","4. Numbers of products\n","5. Numbers of Sales Agents\n","\n","### B. Work on the insights by creating models(Note that creating models in data analysis is different from building models in machine learning)\n","1. Total monthly revenue by Year\n","2. Total revenue by branch\n","3. Total revenue by products\n","4. Total revenue by sales agent\n","5. Total revenue by week\n","6. Total revenue by month\n","7. Trends of sales\n","\n","### C. Build your dash board\n","1. Add the title of your analysis.\n","2. Add the business/company\n","3. Add your KPI's\n","4. Add Charts with appropriate labelling\n","5. Add your slicer if you are working with streamlit or excel or PowerBi or Tableau to make your dashboard interactive(if not, exclude it)\n","\n","### C. Report your insights\n","1. Start with the an executive summary briefly explaining what you and briefly introducing the KPI's.\n","2. Explain your insights in a narative and relatable way using your visuals.\n","\n","### D. Make recommendation\n","1. What should the business owner to increase monthly sales\n","2. Which of the brannches should be given more attention\n","3. Which products should be removed from the stock, which products should be purchased more\n","4. Which of the sales agents should be given more incentives/promoted to sales managers position\n","\n"],"metadata":{"id":"Av7_MOpfTuFE"}},{"cell_type":"markdown","source":["Ronald Coase-\"if you torture the data long enough, it will confess to anything\""],"metadata":{"id":"Eq6Pf3_OWa4q"}},{"cell_type":"markdown","source":["### A. Working on the PKI's\n"],"metadata":{"id":"-nLa9qkXkmgh"}},{"cell_type":"code","source":[],"metadata":{"id":"QDv9P7ogEhdl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#1. Total units sold\n","\n","Total_goods_sold = sales[\"Units\"].sum()\n","print(f\"Total goods sold: {Total_goods_sold} units\")"],"metadata":{"id":"6DCjVK6PPBI6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#2. Total Revenue\n","Total_Revenue = sales[\"Revenue(N)\"].sum()\n","print(f\"Total Revenue: N{Total_Revenue}\")"],"metadata":{"id":"3MemXQzdlitv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#3. Average Revenue per unit\n","## using \"round() function to approximate to 2 decimal place\"\n","Average_revenue_per_unit = round(Total_Revenue / Total_goods_sold,2)\n","print(f\"Average Revenue per unit: N{Average_revenue_per_unit}\")"],"metadata":{"id":"FrxZGVDMluqG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#4. Numbers of products\n","## using the .nunique() shows the numbers of unique values\n","Numbers_of_products = sales[\"Products\"].nunique()\n","print(f\"Numbers of products: {Numbers_of_products}\")"],"metadata":{"id":"z1mP12WCmeT3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#5. Numbers of Sales Agents\n","Numbers_of_sales_agents = sales[\"Sales Agent\"].nunique()\n","print(f\"Numbers of Sales Agents: {Numbers_of_sales_agents}\")"],"metadata":{"id":"u7FNChcqnozo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##B. Work on the insights by creating models and plotting their charts."],"metadata":{"id":"i-br0R9un9AH"}},{"cell_type":"code","source":["# Set index using the date column\n","sales.set_index(\"Date\", inplace=True)"],"metadata":{"id":"PvjbPHJMF1gd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Class Task1: Calculate the Total Monthly revenue for year 2015 and plot the chart using 3 visualization packages in python"],"metadata":{"id":"ScmTc_bfMdeS"}},{"cell_type":"markdown","source":[],"metadata":{"id":"OJUFyO6LMyBt"}},{"cell_type":"code","source":["sales.Year.unique()"],"metadata":{"id":"oCOlGQMrI127"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sales_2015 = sales[sales[\"Year\"] == 2015]"],"metadata":{"id":"BEkdom-nJg_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#1. Filtering\n","#2. Grouping\n","#3. Visuals\n","\n","# lets start analysing this dataset for insights\n","\n","\n","\n","\n","\n","# 1. Monthly revenue in 2015\n","\n","# step1: Filter for 2015\n","\n","\n","\n","sales_2015 = sales[sales[\"Year\"] == 2015]\n","sales_2015.head(3)"],"metadata":{"id":"hDF0yunEG6Ak"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step2:\n","# I am using the .sort_index() to arrange the output, so the arrangement is done base on the index\n","Total_monthly_revenue = sales_2015.groupby(\"Month\")[\"Revenue(N)\"].sum().sort_index()\n","Total_monthly_revenue"],"metadata":{"id":"UrIHHN6tJDl0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# I am using the .sort_values() to arrange the output, so the arrangement is done base on the values\n","\n","Total_monthly_revenue = sales_2015.groupby(\"Month\")[\"Revenue(N)\"].sum().sort_values(ascending = False)\n","Total_monthly_revenue"],"metadata":{"id":"8zdyZXuIOaOs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# lets put this in a plot using pandas\n","Total_monthly_revenue.plot(kind = \"bar\",xlabel = \"Month\", ylabel =\"Revenue(N)\")"],"metadata":{"id":"nazymC2pIDnX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# lets use matlplotlib\n","plt.bar(Total_monthly_revenue.index, Total_monthly_revenue.values)\n","plt.xlabel(\"Month\")\n","plt.ylabel(\"Revenue(N)\")\n","plt.title(\"Monthly Revenue in 2015\")\n","plt.xticks(rotation = 45)\n","plt.show()"],"metadata":{"id":"jKxq-UZlK3kl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Student Task1: Follow the same step and calculate the monthly revenue for 2014 and plot that charts using the 3 visualization packages in python."],"metadata":{"id":"w_ehVOcHMAvS"}},{"cell_type":"code","source":["#2. Total revenue by branch\n","\n","# lest check the branches we have first\n","sales[\"Branch\"].unique()"],"metadata":{"id":"BJeHWgl6L_Cb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Total_revenue_by_branch = sales.groupby(\"Branch\")[\"Revenue(N)\"].sum().sort_values(ascending = False)\n","Total_revenue_by_branch"],"metadata":{"id":"D5ihMtj5pgDW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot the chart for Total Revenue by branch using matplotlib\n","plt.pie(Total_revenue_by_branch.values, labels=Total_revenue_by_branch.index, autopct='%1.1f%%')\n","plt.xlabel(\"Branch\")\n","plt.ylabel(\"Revenue(N)\")\n","plt.title(\"Total Revenue by Branch\")\n","plt.show()"],"metadata":{"id":"7rl51StqpiIW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Total revenue by products\n","## lers check the products available first\n","sales[\"Products\"].unique()\n"],"metadata":{"id":"giKYesl4p38B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"syuz5HoqGMpu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Total_revenue_by_product = sales.groupby(\"Products\")[\"Revenue(N)\"].sum().sort_values(ascending = False)\n","Total_revenue_by_product"],"metadata":{"id":"DmowuIXurEt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LEts plot\n","plt.pie(Total_revenue_by_product.values, labels=Total_revenue_by_product.index, autopct='%1.1f%%')\n","plt.xlabel(\"Product\")\n","plt.ylabel(\"Revenue(N)\")\n","plt.title(\"Total Revenue by Product\")\n","plt.show()"],"metadata":{"id":"CPnfed1nrL_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#3. Total revenue by sales agent\n","\n","#Lets check who our sales agents are\n","sales[\"Sales Agent\"].unique()"],"metadata":{"id":"OkFf55tOrhTV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Total_revenue_by_sales_agent = sales.groupby(\"Sales Agent\")[\"Revenue(N)\"].sum().sort_values(ascending = False)\n","Total_revenue_by_sales_agent"],"metadata":{"id":"UZo5pP1yrtFe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# lets plot using seaborn barchart\n","sns.barplot(x = Total_revenue_by_sales_agent.values, y = Total_revenue_by_sales_agent.index, orient = \"h\")"],"metadata":{"id":"LUcAhxzxr0kf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#4. Total revenue by week\n","Total_revenue_by_week = sales.groupby(\"Week\")[\"Revenue(N)\"].sum().sort_values(ascending = False)\n","Total_revenue_by_week"],"metadata":{"id":"unrQ9kDqsbg8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# lets plot this using line chart\n","plt.plot(Total_revenue_by_week.index, Total_revenue_by_week.values)\n","plt.xlabel(\"Week\")\n","plt.ylabel(\"Revenue(N)\")\n","plt.title(\"Total Revenue by Week\")\n","plt.show()"],"metadata":{"id":"AeXW4tj8smV8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#5. Total revenue by month\n","Total_revenue_by_month = sales.groupby(\"Month\")[\"Revenue(N)\"].sum().sort_values(ascending = False)\n","Total_revenue_by_month"],"metadata":{"id":"gXIZvYzAtg_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot using searborn line chart\n","sns.lineplot(x = Total_revenue_by_month.index, y = Total_revenue_by_month.values)\n","plt.xlabel(\"Month\")\n","plt.xticks(rotation = 45)\n","plt.ylabel(\"Revenue(N)\")\n","plt.title(\"Total Revenue by Month\")\n","plt.show()"],"metadata":{"id":"YJuWJiyWtmdk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#6. Trends of sales\n","Trends_of_sales_over_the_year = sales.groupby([\"Year\",\"Month\"])[\"Revenue(N)\"].sum().reset_index()\n","Trends_of_sales_over_the_year"],"metadata":{"id":"Z9vvEznLuNl8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# lets plot\n","plt.plot(Trends_of_sales_over_the_year[\"Month\"], Trends_of_sales_over_the_year[\"Revenue(N)\"])"],"metadata":{"id":"sfjBmJbtufG-"},"execution_count":null,"outputs":[]}]}